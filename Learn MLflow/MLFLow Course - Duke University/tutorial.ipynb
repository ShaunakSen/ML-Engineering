{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOps Tools: MLflow and Hugging Face\n",
    "\n",
    "> https://www.coursera.org/learn/mlops-mlflow-huggingface-duke/home/week/1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param, log_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEBUG'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_param(\"threshold\", 3)\n",
    "log_param(\"verbosity\", \"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_metric(\"timestamp\", 3000)\n",
    "log_metric(\"TTC\", 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_artifact('./data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next task we would like to track some random metrics\n",
    "\n",
    "Let us first  create an experiment:\n",
    "\n",
    "```\n",
    "> mlflow experiments create --experiment-name log-metrics-demo\n",
    "> Created experiment 'log-metrics-demo' with id 384253852139107280\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/shaunaksen/Documents/personal-projects/ML_Deployment/Learn%20MLflow/MLFLow%20Course%20-%20Duke%20University/mlruns/384253852139107280', creation_time=1690609937121, experiment_id='384253852139107280', last_update_time=1690609937121, lifecycle_stage='active', name='log-metrics-demo', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"log-metrics-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk 87\n",
      "disk 78\n",
      "disk 34\n",
      "ram 77\n",
      "disk 82\n",
      "disk 19\n",
      "ram 51\n",
      "cpu 47\n",
      "disk 47\n",
      "cpu 47\n"
     ]
    }
   ],
   "source": [
    "# lets log some metrics\n",
    "metric_names = [\"cpu\", \"ram\", \"disk\"]\n",
    "percentages = [i for i in range(0, 101)]\n",
    "\n",
    "for i in range(10):\n",
    "    print (choice(metric_names), choice(percentages))\n",
    "    log_metric(key=choice(metric_names), value=choice(percentages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically what happened here is\n",
    "- we created a new experiment\n",
    "- we set this experiment in mlflow\n",
    "- we logged a bunch of metrics under this experiment\n",
    "\n",
    "So if you see in /mlruns, there should be a folder corresponding to the id of the experiment we just created\n",
    "\n",
    "![](https://imgur.com/En296nb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if an active run exists, end it\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/shaunaksen/Documents/personal-projects/ML_Deployment/Learn%20MLflow/MLFLow%20Course%20-%20Duke%20University/mlruns/384253852139107280', creation_time=1690609937121, experiment_id='384253852139107280', last_update_time=1690609937121, lifecycle_stage='active', name='log-metrics-demo', tags={}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"log-metrics-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets log some metrics\n",
    "metric_names = [\"cpu\"]\n",
    "percentages = [i for i in range(0, 101)]\n",
    "\n",
    "with mlflow.start_run(run_name=\"cpu_new\"):\n",
    "\n",
    "    for i in range(400):\n",
    "        # print (choice(metric_names), choice(percentages))\n",
    "        log_metric(key=\"cpu_new\", value=choice(percentages))\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query the metrics using the mlflow UI search box:\n",
    "\n",
    "![](https://imgur.com/GszAvYj.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shaunak_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
